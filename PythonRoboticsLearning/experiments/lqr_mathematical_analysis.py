"""
LQR æœ€ä¼˜æ§åˆ¶çš„æ•°å­¦æ¨å¯¼æ¼”ç¤º
è¯¦ç»†å±•ç¤ºæœ€ä¼˜æ§åˆ¶é‡ã€å¢ç›ŠçŸ©é˜µKå’Œæœ€å°ä»£ä»·çš„å…³ç³»

å‚è€ƒæ–‡çŒ®ï¼š
- Modern Control Engineering (Ogata)
- Optimal Control Theory (Anderson & Moore)
- Linear Optimal Control (Athans & Falb)
"""

import sys
sys.path.insert(0, '/home/zhufeng/code/PythonRobotics/PythonRobotics')

import numpy as np
import matplotlib.pyplot as plt
import scipy.linalg as la
import math

print("ğŸ“ LQR Optimal Control: Mathematical Relationship Deep Dive")
print("=" * 70)

# 1. åŸºæœ¬ç³»ç»Ÿå®šä¹‰
print("\nğŸ“š 1. System Definition and Problem Formulation")
print("-" * 50)

# ç¤ºä¾‹ç³»ç»Ÿï¼šåŒç§¯åˆ†å™¨ç³»ç»Ÿ (è½¦è¾†æ¨ªå‘åŠ¨åŠ›å­¦çš„ç®€åŒ–æ¨¡å‹)
A = np.array([[1.0, 0.1],    # ä½ç½®-é€Ÿåº¦ç³»ç»Ÿ
              [0.0, 1.0]])   # dt = 0.1

B = np.array([[0.005],       # æ§åˆ¶è¾“å…¥åˆ°ä½ç½®
              [0.1]])        # æ§åˆ¶è¾“å…¥åˆ°é€Ÿåº¦

Q = np.array([[10.0, 0.0],   # ä½ç½®æƒé‡
              [0.0,  1.0]])  # é€Ÿåº¦æƒé‡

R = np.array([[1.0]])        # æ§åˆ¶æƒé‡

print(f"System matrix A:\n{A}")
print(f"Input matrix B:\n{B}")
print(f"State weight Q:\n{Q}")
print(f"Control weight R:\n{R}")

# 2. æ±‚è§£ DARE æ–¹ç¨‹
print("\nğŸ”¬ 2. Solving Discrete Algebraic Riccati Equation (DARE)")
print("-" * 60)

def solve_DARE_detailed(A, B, Q, R, show_steps=True):
    """è¯¦ç»†æ±‚è§£DAREï¼Œæ˜¾ç¤ºè¿­ä»£è¿‡ç¨‹"""
    print("DARE: X = A'XA - A'XB(R + B'XB)^(-1)B'XA + Q")

    X = Q.copy()  # åˆå§‹çŒœæµ‹
    max_iter = 100
    eps = 1e-6

    if show_steps:
        print(f"Initial guess Xâ‚€:\n{X}")

    for i in range(max_iter):
        # DARE è¿­ä»£å…¬å¼
        AXA = A.T @ X @ A
        AXB = A.T @ X @ B
        BXB_R = R + B.T @ X @ B
        BXA = B.T @ X @ A

        try:
            inv_term = la.inv(BXB_R)
            X_new = AXA - AXB @ inv_term @ BXA + Q
        except la.LinAlgError:
            print(f"âŒ Singular matrix at iteration {i}")
            break

        # æ£€æŸ¥æ”¶æ•›
        error = np.max(np.abs(X_new - X))

        if show_steps and i < 5:  # åªæ˜¾ç¤ºå‰5æ¬¡è¿­ä»£
            print(f"\nIteration {i+1}:")
            print(f"  X_{i+1}:\n  {X_new}")
            print(f"  Error: {error:.8f}")

        if error < eps:
            if show_steps:
                print(f"\nâœ… Converged after {i+1} iterations")
                print(f"Final solution X:\n{X_new}")
            break

        X = X_new

    return X_new

# æ±‚è§£ DARE
P = solve_DARE_detailed(A, B, Q, R)

# 3. è®¡ç®—æœ€ä¼˜å¢ç›ŠçŸ©é˜µ K
print("\nâš¡ 3. Computing Optimal Gain Matrix K")
print("-" * 45)

# K = (R + B'PB)^(-1) * B'PA
BPB_R = R + B.T @ P @ B
BPA = B.T @ P @ A

K = la.inv(BPB_R) @ BPA

print("Gain matrix formula: K = (R + B'PB)^(-1) * B'PA")
print(f"\nB'PB + R:\n{BPB_R}")
print(f"B'PA:\n{BPA}")
print(f"\nğŸ¯ Optimal gain K:\n{K}")
print(f"K dimensions: {K.shape}")

# 4. æœ€ä¼˜æ§åˆ¶å¾‹
print("\nğŸ® 4. Optimal Control Law")
print("-" * 30)

print("Optimal control law: u* = -K * x")
print(f"For our system: u* = -[{K[0,0]:.4f}  {K[0,1]:.4f}] * [position; velocity]")
print(f"Physical meaning:")
print(f"  - Position feedback: {-K[0,0]:.4f} (proportional control)")
print(f"  - Velocity feedback: {-K[0,1]:.4f} (derivative control)")

# 5. æœ€å°ä»£ä»·çš„è®¡ç®—
print("\nğŸ’° 5. Minimum Cost Analysis")
print("-" * 35)

def calculate_min_cost_analytical(x0, P):
    """è§£æè®¡ç®—æœ€å°ä»£ä»·"""
    return x0.T @ P @ x0

def calculate_min_cost_simulation(x0, A, B, K, Q, R, steps=100):
    """ä»¿çœŸè®¡ç®—å®é™…ä»£ä»·"""
    x = x0.copy()
    total_cost = 0.0

    trajectory_x = []
    trajectory_u = []
    costs = []

    for k in range(steps):
        # æœ€ä¼˜æ§åˆ¶
        u = -K @ x

        # è®¡ç®—ç¬æ—¶ä»£ä»·
        stage_cost = x.T @ Q @ x + u.T @ R @ u
        total_cost += stage_cost[0,0]

        # è®°å½•æ•°æ®
        trajectory_x.append(x.copy())
        trajectory_u.append(u.copy())
        costs.append(stage_cost[0,0])

        # çŠ¶æ€æ›´æ–°
        x = A @ x + B @ u

        # æ£€æŸ¥æ”¶æ•›
        if np.linalg.norm(x) < 1e-10:
            break

    return total_cost, trajectory_x, trajectory_u, costs

# æµ‹è¯•ä¸åŒåˆå§‹çŠ¶æ€
test_states = [
    np.array([[1.0], [0.0]]),     # åªæœ‰ä½ç½®è¯¯å·®
    np.array([[0.0], [1.0]]),     # åªæœ‰é€Ÿåº¦è¯¯å·®
    np.array([[1.0], [1.0]]),     # ä½ç½®å’Œé€Ÿåº¦è¯¯å·®
    np.array([[2.0], [-0.5]])     # å¤æ‚åˆå§‹çŠ¶æ€
]

print("Testing minimum cost for different initial states:")
print("Initial State    | Analytical J* | Simulation J | Error")
print("-" * 55)

for i, x0 in enumerate(test_states):
    # è§£æè§£
    J_analytical = calculate_min_cost_analytical(x0, P)[0,0]

    # ä»¿çœŸè§£
    J_simulation, traj_x, traj_u, costs = calculate_min_cost_simulation(x0, A, B, K, Q, R)

    error = abs(J_analytical - J_simulation)

    print(f"[{x0[0,0]:4.1f}, {x0[1,0]:4.1f}]      | {J_analytical:9.4f}   | {J_simulation:8.4f}   | {error:.2e}")

# 6. å…³é”®å…³ç³»çš„å¯è§†åŒ–
print("\nğŸ“Š 6. Visualizing Key Relationships")
print("-" * 40)

def visualize_relationships():
    """å¯è§†åŒ–æœ€ä¼˜æ§åˆ¶å…³ç³»"""

    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('LQR Optimal Control: Mathematical Relationships', fontsize=16)

    # æµ‹è¯•çŠ¶æ€
    x0 = np.array([[2.0], [1.0]])
    J_opt, traj_x, traj_u, costs = calculate_min_cost_simulation(x0, A, B, K, Q, R, steps=50)

    # æå–è½¨è¿¹æ•°æ®
    positions = [x[0,0] for x in traj_x]
    velocities = [x[1,0] for x in traj_x]
    controls = [u[0,0] for u in traj_u]
    time_steps = range(len(positions))

    # 1. çŠ¶æ€è½¨è¿¹
    ax1 = axes[0, 0]
    ax1.plot(time_steps, positions, 'b-', label='Position', linewidth=2)
    ax1.plot(time_steps, velocities, 'r-', label='Velocity', linewidth=2)
    ax1.set_xlabel('Time Step k')
    ax1.set_ylabel('State Value')
    ax1.set_title('Optimal State Trajectory')
    ax1.legend()
    ax1.grid(True)

    # 2. æ§åˆ¶è¾“å…¥
    ax2 = axes[0, 1]
    time_control = time_steps[:len(controls)]  # ç¡®ä¿é•¿åº¦åŒ¹é…
    ax2.plot(time_control, controls, 'g-', linewidth=2)
    ax2.set_xlabel('Time Step k')
    ax2.set_ylabel('Control Input u')
    ax2.set_title('Optimal Control Input')
    ax2.grid(True)

    # 3. ç¬æ—¶ä»£ä»·
    ax3 = axes[0, 2]
    time_costs = time_steps[:len(costs)]  # ç¡®ä¿é•¿åº¦åŒ¹é…
    ax3.semilogy(time_costs, costs, 'purple', linewidth=2)
    ax3.set_xlabel('Time Step k')
    ax3.set_ylabel('Stage Cost (log scale)')
    ax3.set_title('Stage Cost Evolution')
    ax3.grid(True)

    # 4. ç›¸å¹³é¢å›¾
    ax4 = axes[1, 0]
    ax4.plot(positions, velocities, 'b-', linewidth=2, marker='o', markersize=3)
    ax4.plot(positions[0], velocities[0], 'go', markersize=8, label='Start')
    ax4.plot(0, 0, 'ro', markersize=8, label='Target')
    ax4.set_xlabel('Position')
    ax4.set_ylabel('Velocity')
    ax4.set_title('Phase Plane Trajectory')
    ax4.legend()
    ax4.grid(True)

    # 5. æ§åˆ¶ vs çŠ¶æ€å…³ç³»
    ax5 = axes[1, 1]
    state_norms = [np.linalg.norm(x) for x in traj_x[:len(traj_u)]]  # ç¡®ä¿é•¿åº¦åŒ¹é…
    control_values = [abs(u[0,0]) for u in traj_u]
    ax5.plot(state_norms, control_values, 'mo-', linewidth=2)
    ax5.set_xlabel('State Norm ||x||')
    ax5.set_ylabel('Control Magnitude |u|')
    ax5.set_title('Control vs State Relationship')
    ax5.grid(True)

    # 6. KçŸ©é˜µå¯¹ä»£ä»·çš„å½±å“
    ax6 = axes[1, 2]

    # æµ‹è¯•ä¸åŒçš„Kå€¼å¯¹ä»£ä»·çš„å½±å“
    k1_range = np.linspace(0.5*K[0,0], 2.0*K[0,0], 20)
    k2_range = np.linspace(0.5*K[0,1], 2.0*K[0,1], 20)

    costs_k1 = []
    costs_k2 = []

    for k1 in k1_range:
        K_test = np.array([[k1, K[0,1]]])
        J_test, _, _, _ = calculate_min_cost_simulation(x0, A, B, K_test, Q, R)
        costs_k1.append(J_test)

    for k2 in k2_range:
        K_test = np.array([[K[0,0], k2]])
        J_test, _, _, _ = calculate_min_cost_simulation(x0, A, B, K_test, Q, R)
        costs_k2.append(J_test)

    ax6.plot(k1_range, costs_k1, 'b-', label=f'Varying Kâ‚ (Kâ‚‚={K[0,1]:.3f})', linewidth=2)
    ax6.plot(k2_range, costs_k2, 'r-', label=f'Varying Kâ‚‚ (Kâ‚={K[0,0]:.3f})', linewidth=2)
    ax6.axvline(K[0,0], color='b', linestyle='--', alpha=0.7, label='Optimal Kâ‚')
    ax6.axvline(K[0,1], color='r', linestyle='--', alpha=0.7, label='Optimal Kâ‚‚')
    ax6.set_xlabel('Gain Value')
    ax6.set_ylabel('Total Cost')
    ax6.set_title('Cost vs Gain Sensitivity')
    ax6.legend()
    ax6.grid(True)

    plt.tight_layout()
    plt.savefig('/home/zhufeng/code/PythonRobotics/PythonRoboticsLearning/experiments/lqr_optimal_control_relationships.png',
                dpi=300, bbox_inches='tight')

    return fig

# ç”Ÿæˆå¯è§†åŒ–
fig = visualize_relationships()

# 7. ç†è®ºéªŒè¯
print("\nğŸ” 7. Theoretical Verification")
print("-" * 35)

def verify_bellman_equation(A, B, P, Q, R, K):
    """éªŒè¯è´å°”æ›¼æ–¹ç¨‹"""
    print("Verifying Bellman equation:")
    print("P = Q + K'RK + (A-BK)'P(A-BK)")

    # é—­ç¯ç³»ç»ŸçŸ©é˜µ
    A_cl = A - B @ K

    # è®¡ç®—è´å°”æ›¼æ–¹ç¨‹å³è¾¹
    bellman_rhs = Q + K.T @ R @ K + A_cl.T @ P @ A_cl

    # è®¡ç®—è¯¯å·®
    bellman_error = np.max(np.abs(P - bellman_rhs))

    print(f"Left side (P):\n{P}")
    print(f"Right side:\n{bellman_rhs}")
    print(f"Maximum error: {bellman_error:.2e}")

    if bellman_error < 1e-10:
        print("âœ… Bellman equation satisfied!")
    else:
        print("âŒ Bellman equation not satisfied")

    return bellman_error

def verify_optimality_condition(A, B, P, R, K):
    """éªŒè¯æœ€ä¼˜æ€§æ¡ä»¶"""
    print("\nVerifying optimality condition:")
    print("K = (R + B'PB)^(-1) B'PA")

    # è®¡ç®—ç†è®ºæœ€ä¼˜å¢ç›Š
    K_theory = la.inv(R + B.T @ P @ B) @ (B.T @ P @ A)

    # è®¡ç®—è¯¯å·®
    K_error = np.max(np.abs(K - K_theory))

    print(f"Computed K:\n{K}")
    print(f"Theoretical K:\n{K_theory}")
    print(f"Maximum error: {K_error:.2e}")

    if K_error < 1e-10:
        print("âœ… Optimality condition satisfied!")
    else:
        print("âŒ Optimality condition not satisfied")

    return K_error

# æ‰§è¡ŒéªŒè¯
bellman_err = verify_bellman_equation(A, B, P, Q, R, K)
optimal_err = verify_optimality_condition(A, B, P, R, K)

# 8. æ ¸å¿ƒå…³ç³»æ€»ç»“
print("\nğŸ¯ 8. Core Mathematical Relationships Summary")
print("-" * 55)

print("""
ğŸ“ FUNDAMENTAL RELATIONSHIPS:

1. OPTIMAL CONTROL LAW:
   u*(k) = -KÂ·x(k)

   where K is the optimal gain matrix that minimizes the cost function.

2. RICCATI EQUATION (DARE):
   P = A'PA - A'PB(R + B'PB)â»Â¹B'PA + Q

   P is the solution that gives the minimum cost for any initial state.

3. OPTIMAL GAIN:
   K = (R + B'PB)â»Â¹B'PA

   This gain balances state regulation (via Q) and control effort (via R).

4. MINIMUM COST:
   J*(xâ‚€) = xâ‚€'Pxâ‚€

   The minimum achievable cost from initial state xâ‚€.

5. BELLMAN OPTIMALITY:
   P = Q + K'RK + (A-BK)'P(A-BK)

   This ensures the solution satisfies the principle of optimality.

ğŸ”— KEY INSIGHTS:

â€¢ K represents the optimal feedback policy
â€¢ P encodes the cost-to-go from any state
â€¢ The relationships are mutually consistent
â€¢ Higher Q weights â†’ larger K â†’ more aggressive control
â€¢ Higher R weights â†’ smaller K â†’ gentler control
â€¢ P determines both the optimal gain K and minimum cost J*
""")

# 9. å®é™…å·¥ç¨‹æ„ä¹‰
print("\nğŸ—ï¸ 9. Engineering Implications")
print("-" * 35)

print(f"""
PRACTICAL MEANINGS:

ğŸ® Control Gain K = [{K[0,0]:.4f}, {K[0,1]:.4f}]:
   â€¢ Position feedback: {K[0,0]:.4f} (like a spring force)
   â€¢ Velocity feedback: {K[0,1]:.4f} (like a damper force)
   â€¢ Total control: u = -{K[0,0]:.4f}Â·pos - {K[0,1]:.4f}Â·vel

ğŸ’° Cost Matrix P:
   â€¢ P[0,0] = {P[0,0]:.4f}: Cost per unit positionÂ²
   â€¢ P[1,1] = {P[1,1]:.4f}: Cost per unit velocityÂ²
   â€¢ P[0,1] = {P[0,1]:.4f}: Cross-coupling cost

âš–ï¸ Design Trade-offs:
   â€¢ Q â†‘ â†’ K â†‘ â†’ More aggressive control, lower tracking error
   â€¢ R â†‘ â†’ K â†“ â†’ Gentler control, higher tracking error
   â€¢ P determines the Pareto frontier of this trade-off
""")

plt.show()

print("\n" + "=" * 70)
print("ğŸ“ LQR Mathematical Relationships - Analysis Complete!")
print("=" * 70)